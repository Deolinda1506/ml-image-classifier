{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Image Classifier Pipeline\n",
        "\n",
        "This notebook demonstrates the complete Machine Learning pipeline for image classification (Cat vs Dog).\n",
        "\n",
        "## Overview\n",
        "- Data acquisition and preprocessing\n",
        "- Model creation and training\n",
        "- Model evaluation and optimization\n",
        "- Visualization and analysis\n",
        "- Model deployment preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../src\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Import our custom modules\n",
        "from preprocessing import ImagePreprocessor\n",
        "from model import ImageClassifier\n",
        "from prediction import PredictionService\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ImagePreprocessor' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize preprocessor\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m \u001b[43mImagePreprocessor\u001b[49m(img_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessor initialized with image size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreprocessor\u001b[38;5;241m.\u001b[39mimg_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass names: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreprocessor\u001b[38;5;241m.\u001b[39mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImagePreprocessor' is not defined"
          ]
        }
      ],
      "source": [
        "# Initialize preprocessor\n",
        "preprocessor = ImagePreprocessor(img_size=(224, 224), batch_size=32)\n",
        "print(f\"Preprocessor initialized with image size: {preprocessor.img_size}\")\n",
        "print(f\"Class names: {preprocessor.class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'preprocessor' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241m.\u001b[39mload_dataset_from_flat_structure(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "X_train, y_train, X_test, y_test = preprocessor.load_dataset_from_flat_structure('../data')\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Test labels shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize dataset samples\n",
        "print(\"Visualizing dataset samples...\")\n",
        "preprocessor.visualize_dataset(X_train, y_train, num_samples=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot class distribution\n",
        "print(\"Analyzing class distribution...\")\n",
        "preprocessor.plot_class_distribution(y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Analysis and Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze image characteristics\n",
        "def analyze_image_characteristics(X_train, y_train):\n",
        "    \"\"\"Analyze various characteristics of the images\"\"\"\n",
        "    \n",
        "    # Calculate brightness (mean pixel value)\n",
        "    brightness = np.mean(X_train, axis=(1, 2, 3))\n",
        "    \n",
        "    # Calculate contrast (standard deviation of pixel values)\n",
        "    contrast = np.std(X_train, axis=(1, 2, 3))\n",
        "    \n",
        "    # Calculate color distribution\n",
        "    red_channel = np.mean(X_train[:, :, :, 0], axis=(1, 2))\n",
        "    green_channel = np.mean(X_train[:, :, :, 1], axis=(1, 2))\n",
        "    blue_channel = np.mean(X_train[:, :, :, 2], axis=(1, 2))\n",
        "    \n",
        "    # Create DataFrame for analysis\n",
        "    df = pd.DataFrame({\n",
        "        'class': [preprocessor.class_names[y] for y in y_train],\n",
        "        'brightness': brightness,\n",
        "        'contrast': contrast,\n",
        "        'red_channel': red_channel,\n",
        "        'green_channel': green_channel,\n",
        "        'blue_channel': blue_channel\n",
        "    })\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Perform analysis\n",
        "print(\"Analyzing image characteristics...\")\n",
        "image_analysis = analyze_image_characteristics(X_train, y_train)\n",
        "print(\"\\nImage Analysis Summary:\")\n",
        "print(image_analysis.groupby('class').describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize image characteristics by class\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Image Characteristics Analysis by Class', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Brightness\n",
        "axes[0, 0].hist(image_analysis[image_analysis['class'] == 'cat']['brightness'], \n",
        "                alpha=0.7, label='Cat', bins=20)\n",
        "axes[0, 0].hist(image_analysis[image_analysis['class'] == 'dog']['brightness'], \n",
        "                alpha=0.7, label='Dog', bins=20)\n",
        "axes[0, 0].set_title('Brightness Distribution')\n",
        "axes[0, 0].set_xlabel('Brightness')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Contrast\n",
        "axes[0, 1].hist(image_analysis[image_analysis['class'] == 'cat']['contrast'], \n",
        "                alpha=0.7, label='Cat', bins=20)\n",
        "axes[0, 1].hist(image_analysis[image_analysis['class'] == 'dog']['contrast'], \n",
        "                alpha=0.7, label='Dog', bins=20)\n",
        "axes[0, 1].set_title('Contrast Distribution')\n",
        "axes[0, 1].set_xlabel('Contrast')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Red Channel\n",
        "axes[0, 2].hist(image_analysis[image_analysis['class'] == 'cat']['red_channel'], \n",
        "                alpha=0.7, label='Cat', bins=20)\n",
        "axes[0, 2].hist(image_analysis[image_analysis['class'] == 'dog']['red_channel'], \n",
        "                alpha=0.7, label='Dog', bins=20)\n",
        "axes[0, 2].set_title('Red Channel Distribution')\n",
        "axes[0, 2].set_xlabel('Red Channel Value')\n",
        "axes[0, 2].set_ylabel('Frequency')\n",
        "axes[0, 2].legend()\n",
        "\n",
        "# Green Channel\n",
        "axes[1, 0].hist(image_analysis[image_analysis['class'] == 'cat']['green_channel'], \n",
        "                alpha=0.7, label='Cat', bins=20)\n",
        "axes[1, 0].hist(image_analysis[image_analysis['class'] == 'dog']['green_channel'], \n",
        "                alpha=0.7, label='Dog', bins=20)\n",
        "axes[1, 0].set_title('Green Channel Distribution')\n",
        "axes[1, 0].set_xlabel('Green Channel Value')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# Blue Channel\n",
        "axes[1, 1].hist(image_analysis[image_analysis['class'] == 'cat']['blue_channel'], \n",
        "                alpha=0.7, label='Cat', bins=20)\n",
        "axes[1, 1].hist(image_analysis[image_analysis['class'] == 'dog']['blue_channel'], \n",
        "                alpha=0.7, label='Dog', bins=20)\n",
        "axes[1, 1].set_title('Blue Channel Distribution')\n",
        "axes[1, 1].set_xlabel('Blue Channel Value')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "# Box plot of brightness by class\n",
        "image_analysis.boxplot(column='brightness', by='class', ax=axes[1, 2])\n",
        "axes[1, 2].set_title('Brightness by Class')\n",
        "axes[1, 2].set_xlabel('Class')\n",
        "axes[1, 2].set_ylabel('Brightness')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('data_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Insights:\")\n",
        "print(f\"1. Cats tend to have {'higher' if image_analysis.groupby('class')['brightness'].mean()['cat'] > image_analysis.groupby('class')['brightness'].mean()['dog'] else 'lower'} brightness than dogs\")\n",
        "print(f\"2. Dogs have {'higher' if image_analysis.groupby('class')['contrast'].mean()['dog'] > image_analysis.groupby('class')['contrast'].mean()['cat'] else 'lower'} contrast than cats\")\n",
        "print(f\"3. Color channel distributions show {'similar' if abs(image_analysis.groupby('class')['red_channel'].mean()['cat'] - image_analysis.groupby('class')['red_channel'].mean()['dog']) < 0.05 else 'different'} patterns between classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split training data into train and validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train_split.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data generators with augmentation\n",
        "print(\"Creating data generators...\")\n",
        "train_generator, val_generator = preprocessor.create_data_generators(\n",
        "    X_train_split, y_train_split, X_val, y_val\n",
        ")\n",
        "print(\"Data generators created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and build model\n",
        "print(\"Building model...\")\n",
        "classifier = ImageClassifier(model_type='custom')\n",
        "model = classifier.build_model()\n",
        "\n",
        "print(\"Model architecture:\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting model training...\")\n",
        "start_time = datetime.now()\n",
        "\n",
        "history = classifier.train(\n",
        "    train_generator, \n",
        "    val_generator, \n",
        "    epochs=50,\n",
        "    model_save_path='../models/best_model.h5'\n",
        ")\n",
        "\n",
        "end_time = datetime.now()\n",
        "training_duration = (end_time - start_time).total_seconds()\n",
        "\n",
        "print(f\"\\nTraining completed in {training_duration:.2f} seconds\")\n",
        "print(f\"Training completed in {training_duration/60:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "print(\"Plotting training history...\")\n",
        "classifier.plot_training_history(save_path='training_history.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model on test set\n",
        "print(\"Evaluating model on test set...\")\n",
        "metrics = classifier.evaluate_model(X_test, y_test)\n",
        "\n",
        "print(\"\\nTest Set Evaluation Results:\")\n",
        "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
        "\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(metrics['classification_report'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "print(\"Plotting confusion matrix...\")\n",
        "cm = np.array(metrics['confusion_matrix'])\n",
        "classifier.plot_confusion_matrix(cm, save_path='confusion_matrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze misclassifications\n",
        "def analyze_misclassifications(X_test, y_test, y_pred, metrics):\n",
        "    \"\"\"Analyze misclassified images\"\"\"\n",
        "    \n",
        "    # Get misclassified indices\n",
        "    misclassified = np.where(y_test != y_pred)[0]\n",
        "    \n",
        "    print(f\"\\nMisclassification Analysis:\")\n",
        "    print(f\"Total misclassifications: {len(misclassified)}\")\n",
        "    print(f\"Misclassification rate: {len(misclassified)/len(y_test)*100:.2f}%\")\n",
        "    \n",
        "    if len(misclassified) > 0:\n",
        "        # Show some misclassified examples\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "        axes = axes.ravel()\n",
        "        \n",
        "        for i, idx in enumerate(misclassified[:8]):\n",
        "            axes[i].imshow(X_test[idx])\n",
        "            true_class = preprocessor.class_names[y_test[idx]]\n",
        "            pred_class = preprocessor.class_names[y_pred[idx]]\n",
        "            axes[i].set_title(f'True: {true_class}\\nPred: {pred_class}')\n",
        "            axes[i].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    return misclassified\n",
        "\n",
        "# Analyze misclassifications\n",
        "y_pred = np.array(metrics['predictions'])\n",
        "misclassified_indices = analyze_misclassifications(X_test, y_test, y_pred, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Deployment Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final model and metadata\n",
        "print(\"Saving final model and metadata...\")\n",
        "classifier.save_model(\n",
        "    '../models/best_model.h5',\n",
        "    '../models/model_metadata.json'\n",
        ")\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test prediction service\n",
        "print(\"Testing prediction service...\")\n",
        "try:\n",
        "    prediction_service = PredictionService(\n",
        "        '../models/best_model.h5',\n",
        "        '../models/model_metadata.json'\n",
        "    )\n",
        "    \n",
        "    # Test with a sample image\n",
        "    sample_image = X_test[0:1]  # Take first test image\n",
        "    prediction = classifier.predict_single_image(sample_image)\n",
        "    \n",
        "    print(f\"\\nSample Prediction Test:\")\n",
        "    print(f\"Predicted class: {prediction['predicted_class']}\")\n",
        "    print(f\"Confidence: {prediction['confidence']:.4f}\")\n",
        "    print(f\"True class: {preprocessor.class_names[y_test[0]]}\")\n",
        "    print(f\"Prediction correct: {prediction['predicted_class'] == preprocessor.class_names[y_test[0]]}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error testing prediction service: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\" * 60)\n",
        "print(\"ML PIPELINE SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Dataset: {X_train.shape[0]} training, {X_test.shape[0]} test images\")\n",
        "print(f\"Classes: {preprocessor.class_names}\")\n",
        "print(f\"Image size: {preprocessor.img_size}\")\n",
        "print(f\"Model type: {classifier.model_type}\")\n",
        "print(f\"Training time: {training_duration/60:.2f} minutes\")\n",
        "print(f\"\\nFinal Test Results:\")\n",
        "print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "print(f\"  F1 Score: {metrics['f1_score']:.4f}\")\n",
        "print(f\"\\nModel saved to: ../models/best_model.h5\")\n",
        "print(f\"Metadata saved to: ../models/model_metadata.json\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Key insights\n",
        "print(\"\\nKEY INSIGHTS:\")\n",
        "print(\"1. Data preprocessing with augmentation improves model generalization\")\n",
        "print(\"2. Custom CNN architecture performs well for this binary classification task\")\n",
        "print(\"3. Model shows good balance between precision and recall\")\n",
        "print(\"4. Ready for deployment with Flask API and web interface\")\n",
        "print(\"5. Supports real-time prediction and model retraining\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
